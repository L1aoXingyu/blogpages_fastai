<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">TensorRT 使用 Custom Plugin</h1><p class="page-description">如何在 TensorRT 中使用自定义的插件</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-09-09T00:00:00-05:00" itemprop="datePublished">
        Sep 9, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blogpages/categories/#deep learning">deep learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blogpages/categories/#deployment">deployment</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blogpages/categories/#tensorRT">tensorRT</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blogpages/categories/#inference">inference</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blogpages/categories/#onnx">onnx</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#0x0-introduction">0x0 Introduction</a></li>
</ul><h2 id="0x0-introduction">
<a class="anchor" href="#0x0-introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>0x0 Introduction</h2>

<p>在模型开发的流程中，除了训练模型之外，另外一个同样重要的部分就是模型部署，常见的部署方式有两种，一种是直接使用原生的训练框架做推理，另外一种是使用硬件厂商提供的加速器。
一般情况下，可以选择简单易用的第一种方式，但是在对性能有极致要求的边端设备上，就只能选择第二种方式，这个时候就需要设计到模型从训练框架到加速器的转换流程。</p>

<p>目前工业界比较常见的流程是通过 onnx 作为模型的中间表达(IR)，即所有的训练框架(PyTorch, TensorFlow, etc.) 在训练完成之后都转换成 onnx，然后再转换成加速器的 IR，比如 TensorRT 的 engine，虽然这个流程转换并不容易，中间也有很多坑，但是这个流程确实是一个比较通用。</p>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="L1aoXingyu/blogpages"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blogpages/deep%20learning/deployment/tensorrt/inference/onnx/2022/09/09/tensorrt-plugin.html" hidden></a>
</article>
