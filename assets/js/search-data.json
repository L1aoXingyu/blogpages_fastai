{
  
    
        "post0": {
            "title": "L2 regularization 和 weight decay",
            "content": "Introduction . 通常我们在说 weight decay 的时候，都认为也是在说 L2 regularization，那么到底他们的实现是什么以及他们是否等价呢？这篇文章是一个简单的总结。 . weight decay 和 L2 regularization 的原理 . weight decay 的原理是在每次进行梯度更新的时候，额外再减去一个梯度，如果以普通的梯度下降为例，公式如下 . θt+1=(θt−η∇(θt))−λθt=(1−λ)θt−η∇(θt) theta_{t+1} = ( theta_{t} - eta nabla( theta_t)) - lambda theta_t = (1 - lambda) theta_{t} - eta nabla( theta_t)θt+1​=(θt​−η∇(θt​))−λθt​=(1−λ)θt​−η∇(θt​) . 其中 λ lambdaλ 就是 weight decay 中设定的超参数，通常设定比较小。 . L2 regularization 的原理是在计算 loss 的时候增加一个惩罚项，L2 即为增加一个二范数的惩罚项，即 . freg(θt)=f(θt)+λ2∣∣θ∣∣22f^{reg}( theta_t) = f( theta_t) + frac{ lambda}{2} || theta||_2^2freg(θt​)=f(θt​)+2λ​∣∣θ∣∣22​ . 那么这时对参数求导并进行反向传播就可以有下面的公式 . ∂freg/∂θt=∂f/∂θt+λθt partial f^{reg} / partial theta_t = partial f / partial theta_t + lambda theta_t∂freg/∂θt​=∂f/∂θt​+λθt​ . 那么再进行梯度更新的时候 L2 reg 就相当于额外减去 η∗λ∗θt eta * lambda * theta_tη∗λ∗θt​，其中 η etaη 是学习率，λ lambdaλ 是 L2 reg 中设定的超参数 . 通过上面的公式可以看出 L2 reg 和 weight decay 虽然原理上不一致，不过通过推导在数学形式上最后只差一个常数倍，所以是否可以认为 L2 reg 和 weight decay 是等价的呢？ . L2 reg 和 weight decay 等价吗？ . 通过上面的公式可以推导出 L2 reg 和 weight decay 是等价的，不过有一个大前提即上面的公式表达的是最普通的 SGD 更新方式，除了 vanilla SGD 之外，还有很多 variant optimizer 比如 SGDM，RMSprop，Adam 等等，下面我们以 Adam 为例再次进行 L2 reg 和 weight decay 的公式推导。 . Adam 原理 . 首先回顾一下 Adam 的工作原理，给定超参 β1,β2 beta_1, beta_2β1​,β2​ 以及学习率 η etaη，不考虑 L2 reg 和 weight decay 时，Adam 的更新公式如下 . gt←∇ft(θt−1)mt←β1mt−1+(1−β1)gtvt←β2vt−1+(1−β2)gt2m^t←mt/(1−β1t)v^t←vt/(1−β2t)θt←θt−1−ηm^t/(v^t+ϵ)g_t leftarrow nabla f_t( theta_{t-1}) m_t leftarrow beta_1 m_{t-1} + (1 - beta_1) g_t v_t leftarrow beta_2 v_{t-1} + (1 - beta_2) g_t^2 hat{m}_t leftarrow m_t / (1 - beta_1^t) hat{v}_t leftarrow v_t / (1 - beta_2^t) theta_t leftarrow theta_{t-1} - eta hat{m}_t / ( sqrt{ hat{v}_t} + epsilon)gt​←∇ft​(θt−1​)mt​←β1​mt−1​+(1−β1​)gt​vt​←β2​vt−1​+(1−β2​)gt2​m^t​←mt​/(1−β1t​)v^t​←vt​/(1−β2t​)θt​←θt−1​−ηm^t​/(v^t​ . ​+ϵ) . Adam with weight decay and L2 reg . 接下来可以在上面的公式中增加 L2 reg 和 weight decay，其中红色表示 L2 reg，绿色表示 weight decay . . 其中 m^t hat{m}_tm^t​ 是 bias correction，在 t 比较小的时候可以防止 mtm_tmt​ 因为初始值为 0 导致更新较少的问题，同时当 t→∞t rightarrow inftyt→∞ 时 m^t→mt hat{m}_t rightarrow m_tm^t​→mt​，所以在后续的公式中直接用 mtm_tmt​ 来代替 m^t hat{m}_tm^t​ . 通过对公式的进一步展开和对比，可以发现 L2 reg 和 weight decay 之间除了有个常数倍 η(1−β1) eta(1- beta_1)η(1−β1​) 的区别外，一个更大的区别是 v^t sqrt{ hat{v}_t}v^t​​ 作为分母，这里就引入了不一致性，因为当 grad 中某一个分量的值过大时，v^t sqrt{ hat{v}_t}v^t​​ 就会变大，所以导致 l2 reg 作用在对应分量上的结果变小，这其实和 weight decay 的行为是不一致的，因为 weight decay 对所有的参数都应该是相同的惩罚项，所以正是因为自适应学习率等变种 optimizer 的出现导致 l2 reg 也进行了自适应，所以会导致和 weight decay 的结果最终不同。 . 当然因为 l2 reg 是作用了初始梯度上的，而一阶矩 mtm_tmt​ 和二阶矩 vtv_tvt​ 都需要依赖 gtg_tgt​ 进行更新，所以在不断的更新中也会导致他们在 l2 reg 和 weight decay 下的结果不一致，因为这里是一个积累差异，所以在公式中就没有详细展开了。 . 在这篇文章 ICLR19 的论文 DECOUPLED WEIGHT DECAY REGULARIZATION 中详细的进行了理论的推导和分析 l2 reg 和 weight decay 的差异以及最终的结果，最终为这种真正使用 weight decay 的 Adam 取名为 AdamW 作为区分，感兴趣的同学可以直接去阅读原文。 . 到底使用 Adam 还是 AdamW . 之前大多数深度学习框架包括 TensorFlow 和 PyTorch 等都是按照 l2 reg 去实现的 Adam，不过要改为 AdamW 也比较简单，通过上面的分析是否说明我们应该把所有项目中使用的 Adam 都换成 AdamW 呢？ . 我的观点是之前项目中使用的 Adam 可以换成 AdamW 一试效果，如果精度较低就还是使用回 Adam，如果精度提升就换成 AdamW。那么为什么从上面的理论中得到 AdamW 才是正确的实现，但是实际使用 AdamW 也不一定好呢？原因有很多，因为深度神经网络是一个黑盒，没有人能详细的计算出内部的运算原理，同时之前调参和各种 tricks 都是基于 Adam 去做的，已经针对 Adam+l2 reg 的进行了比较细致的优化，这时直接换成 AdamW 可能重新做一些调参工作可以超过之前的结果，不过就不建议去做重复劳动了。 . 在新项目中可以直接使用 AdamW，同时基于 AdamW 进行调参，这样可以尽可能保证得到更好的结果，比如 Bert 就直接使用的 AdamW。 . Ending . 最后希望这篇文章能够让你了解 l2 reg 和 weight decay 之间的区别和联系，如果你有任何建议和问题欢迎在评论去留言，希望这篇文章能够帮助到你们。 . Reference . 都9102年了，别再用Adam + L2 regularization了 - 知乎 (zhihu.com) . | DECOUPLED WEIGHT DECAY REGULARIZATION . | .",
            "url": "https://l1aoxingyu.github.io/blogpages/deep%20learning/tricks/2021/11/05/l2-reg-weight-decay.html",
            "relUrl": "/deep%20learning/tricks/2021/11/05/l2-reg-weight-decay.html",
            "date": " • Nov 5, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "《黑客与画家》读后感",
            "content": "最近读完了一本书，叫《黑客与画家》，其作者 Paul Graham 被誉为硅谷创业之父，是 Lisp 的狂热爱好者，同时使用 Lisp 创立了 Viaweb，帮助个人用户在网上开店，这也是第一个互联网应用程序，在 1998 年被 Yahoo！公司收购。 . Paul 的经历非常传奇，在 Viaweb 被收购之后，也可以在个人网站上撰写血多关于软件和创业的文章，随后身体力行，创立了风险投资公司 Y Combinator，目前已经资助了超过 80 多家创业公司。 . 在《黑客和画家》中，Paul 首先为大众眼中 的“黑客”正名，黑客是 Hacker 的音译，因为名字里面有“黑”，且在报道中总是出现负面新闻，所以大众认为黑客就是对计算机系统和网络进行可以破坏的人。其实真正的黑客主要是指技术高超的程序员，而 Cracker 才是指恶意破坏的人。 . 在书中 Paul 也表达了一些比较前瞻的观点，比如用户像订报纸那样按照使用时间长短订购软件的使用权，而现在订阅模式正越来越流行。也表达了一些比较偏激的观点，比如某一种编程语言就是要优于另外一种编程语言；在高科技行业中，只有失败者采用“业界最佳实践”等等。 . 虽然有一些观念存在争议，不过仍然有一些观点我认为值得推崇，同时可以引人深思，下面列举其中的一些例子。 . 不要盲目从众 . 在第一章中 Paul 指出，在美国一般都是体育出众的小孩儿更受欢迎，而学习成绩比较好的小孩儿往往被称为 “Nerd”，也就是书呆子，作者在小时候也被称为书呆子，收到排挤。 . 长大后，Paul 思考了一下背后的原因，一方面归结于小孩儿在产生良知之前，会认为折磨就是一种娱乐；另一方面的原因就是大家找一个共同的敌人有利于“受欢迎”，就好比一个政客，他想让选民忘记糟糕的国内局势，方法就是为国家找出一个敌人，哪怕敌人并不真的存在，他也可以创造一个出来，所以书呆子就被挑选出来成为欺负的对象。 而书呆子的注意力都放在读书或者观察世界上，他们琢磨如何更聪明而不是如何更受欢迎，这也是书呆子难以融入校园环境的原因。 . 而到了成年人的世界，一切变得不太一样了，人们都变得更加成熟，你所做的每一件事儿都能产生真正意义上的效果，这是发现正确的答案就变得重要了，这正是书呆子的优势所在，也是像比尔·盖茨、扎克伯克这样的人能成功的真正原因。 所以当你发现你和周围的人格格不入，无法融入其中时，比如在学校寝室室友都在翘课打游戏，问你要不要加入他们。这时先不要着急对自我产生怀疑，先思考和确认自己目前追寻的是否是正确的事情，如果是的话，就勇敢去做，不需要迎合他们，完成自我价值的实现才能找到人生真正的意义。而在面对一些不公平的待遇时，也要学会自我调节，不要钻牛角尖，人生有多种可能，无需在一棵树上吊死。 . 编程与思考的关系 . 另外一个比较有意思的点就是编程和思考的关系，我们一般都认为写代码前要先想清楚结构，这样才有助于写出高效的代码。 . 而 Paul 认为 把整个程序想清楚的时间点，应该是在编写代码的同时，而不是在编写代码之前。他认为编程和画画一样，都是一种艺术创作，而画画的过程就是通过不断地涂改最终完成作品，所以编程也不应该在一开始就定好整体的结构，而是应该在写的过程中不断修正。 . 除了快点动手开始写之外，及时反馈也很重要，先做出原型，再逐步加工做出成品，这种方式有利于鼓舞士气，因为它使得你随时都可以看到工作的成效。开发软件的时候，我有一条规则：任何时候，代码都必须能够运行。如果你正在写的代码一个小时之后就可以看到运行结果，这好比让你看到不远处就是唾手可得的奖励，你因此会受到激励和鼓舞。 . 所以先完成一个最小的可行版本，再根据用户的反馈去不断优化，最终才能呈现出质量良好的产品，这也是现在比较流行的 Scrum 理念一致。 . 对工作的思考 . 工作会占据人生三分之一的时间，我们没有理由不好好考虑一下工作对自身的意义。随着现在 996 越来越常态化，work life balance 也离我们越来越遥远，大家似乎每天都很忙碌，但是却越来越缺少时间思考工作对我们来说到底意味着什么。 . Paul 在书中回答了 “工作到底是什么？”这个问题，他指出工作 真正重要的是做出人们需要的东西，而不是加入某个公司。 不过似乎大部分的人在选择工作的时候更多的会看重给的薪水，而不会去考虑自己所做的事对社会的价值。 . 除此之外，Paul 还提出了两个原则，分别是可测量性和放大性，而且他认为，任何一个通过自身努力而致富的个人，在他们身上应该都能同时发现可测量性和可放大性。 工作职位产生的业绩，应该是可测量的，否则没有办法评判谁应该升职加薪；同时如果你做的事情影响的人很少，那么你的工作非常杰出，产生的效应也非常小。 . 另外团队越小，可测量性就越强，因为每个人所做的贡献能够更准确地估计，所以乔布斯曾经说过，创业的成败取决于最早加入公司的那十个人。而大公司就像一艘巨大的船，一千个划船手共同朝着一个方向划船，但是每个人其实并不能看到自己的努力对船航行的影响，同时因为团队太大，所以每一个人的努力都被平均化了。 . 不过小团队的优势并不在于“小”，而在于“精”，可以自由选择你的队友组成“全明星第一阵容”，从而发挥小团队带来的额外激励。这也解释了为什么能力非常强而且在乎回报的人，通常更愿意出去创业。 . 高科技会带来放大性，大多数人因为创造财富而发财的人都是通过开发新技术而实现的，这在科技类和软件类公司非常显然，甚至在一些看上去和科技无关的公司也是同样的道理，比如沃尔玛并不是通过经营零售业而致富，而是因为设计出了一种新型的商店和销售模式。 . 所以我们在选择方向和团队时，也可以以这两个方向为指导，首先所做的工作具有可测量性，同时所做的事情还具有放大效应，这样最终才有机会做出有意义深远的事情，也有机会影响更多的人。 . 结语 . 以上只是我对 Paul 这本书一些个人肤浅的见解，如果大家感兴趣，推荐大家去读一下这本书，也许能够获得更多的收获。 .",
            "url": "https://l1aoxingyu.github.io/blogpages/book%20review/programming/2021/06/02/hackers-and-painters.html",
            "relUrl": "/book%20review/programming/2021/06/02/hackers-and-painters.html",
            "date": " • Jun 2, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "深度学习中的分布式并行介绍",
            "content": "Introduction . 随着深度学习中的数据规模和网络规模越来越大，训练神经网络会耗费越来越多的时间，势必需要从单 GPU 训练向多 GPU 训练甚至多机训练进行扩展。比如在大规模人脸识别中，训练上千万人脸 ID 需要对最后的全连接层做模型并行，而 GPT-3 为代表的大模型更是有 1750 亿参数，需要在多台机器上做流水并行才能训起来。 . 近年来除了算力增长非常迅速外，深度学习框架近也在飞速发展，分布式并行的实现变得越来越成熟，不同的细节实现对最后的性能也有着很大的影响，下面简单介绍一下其中的一些并行方式作为扫盲，如有问题，欢迎拍砖。 . Data Parallel . 第一种并行方式叫做数据并行，也是现在最流行的一种并行方式。当一块 GPU 可以存储下整个模型时，可以采用数据并行的方式获得更准确的梯度，同时还可以加速训练。主要的方式为每个 GPU 复制一份模型，将一个 batch 的样本平均分为多份，分别输入到不同的卡上做并行计算。 . 因为求导以及加和都是线性的，所以数据并行在数学上是等价的。假设一个 batch 有 n 个样本，一共有 k 个 GPU，第 j 个 GPU 分到 $m_j$ 个样本，考虑等分情况，则 $m_j = frac{n}{k}$ ，如果考虑总损失函数 loss 对参数 w 求导，则有 . ∂Loss∂w=1n∑i=1n∂l(xi,yi)∂w=m1n∂[1m1∑i=1m1l(xi,yi)]∂w+m2n∂[1m2∑i=m1+1m2l(xi,yi)]∂w+⋯=m1n∂l1∂w+m2n∂l2∂w+⋯+mkn∂lk∂w=1k[∂l1∂w+∂l2∂w+⋯+∂lk∂w] frac{ partial{Loss}}{ partial w} = frac{1}{n} sum_{i=1}^n frac{ partial{l(x_i, y_i)}}{ partial w} = frac{m_1}{n} frac{ partial [ frac{1}{m_1} sum_{i=1}^{m_1} l(x_i, y_i)]}{ partial w} + frac{m_2}{n} frac{ partial [ frac{1}{m_2} sum_{i=m_1+1}^{m_2} l(x_i, y_i)]}{ partial w} + cdots = frac{m_1}{n} frac{ partial l_1}{ partial w} + frac{m_2}{n} frac{ partial l_2}{ partial w} + cdots + frac{m_k}{n} frac{ partial l_k}{ partial w} = frac{1}{k} [ frac{ partial l_1}{ partial w} + frac{ partial l_2}{ partial w} + cdots + frac{ partial l_k}{ partial w}]∂w∂Loss​=n1​i=1∑n​∂w∂l(xi​,yi​)​=nm1​​∂w∂[m1​1​∑i=1m1​​l(xi​,yi​)]​+nm2​​∂w∂[m2​1​∑i=m1​+1m2​​l(xi​,yi​)]​+⋯=nm1​​∂w∂l1​​+nm2​​∂w∂l2​​+⋯+nmk​​∂w∂lk​​=k1​[∂w∂l1​​+∂w∂l2​​+⋯+∂w∂lk​​] . 从上面的计算公式中可以看出，所有卡上总 batch 的平均梯度，和单卡上 mini-batch 的平均梯度汇总之后在平均的结果是一样的。 . 在 PyTorch 中，数据并行主要有两种实现方式：DataParallel 和 DistributedDataParallel。 . DataParallel . 在 PyTorch 中，DataParallel 的使用非常方便，只需要下面一行代码，就可以将原本单卡的 module 改成多卡的数据并行 . model = nn.DataParallel(model, device_ids=[0,1,2,3]) . DataParallel 的原理可以参考下面的图片 . Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU &amp; Distributed setups . 在前向的计算过程中，将数据平分到不同的卡上，同时将模型也复制到不同的卡上，然后在每张卡上并行做计算，最后在 device[0] 上获取所有卡上的计算结果。 . 在反向的计算过程中，在 device[0] 上用 outputs 和 label 计算相应的 loss ，然后计算 outputs 的梯度，接着将梯度发回到每张卡上，然后在每张卡上并行做反向传播得到对应的梯度，最后再一次将不同卡的梯度收集到 device[0] 上，然后在 device[0] 上做梯度下降更新参数。 . 通过上面的流程，可以发现 device[0] 会比其他 device 使用更多次，而且因为所有的 loss 以及 loss 的梯度都是在 device[0] 上进行的计算的，所以也会出现负载不均衡的问题。 . 有一种简单的方法可以缓解负载均衡问题，就是将 loss 计算放到网络前向中，这样在前向计算结束之后，device[0] 上获取的就是每张卡上 loss 的计算结果，然后再并行的在每张卡上进行反向传播计算梯度，整体计算流和下面的 Parameter Server 类似 . https://d2l.ai/chapter_computational-performance/parameterserver.html . 过程一(红色部分): 各卡分别计算损失和梯度； . 过程二(蓝色部分): 所有梯度整合到 device[0]； . 过程三(绿色部分): device[0] 进行参数更新，分发参数到其他卡上； . Parameter Servers 的核心概念在 [Smola &amp; Narayanamurthy, 2010] 中引入，实现非常简洁，不过整体上还是有一些缺点 . device[0] 会被更多的使用，从而导致 bottleneck 出现； | 负载均衡问题，不同的卡所占的显存不一致； | 通信开销很大，同步策略非常慢，假设有 k 个 GPU，完成一次通信需要时间 t ，如果使用 PS 算法，总共耗时 $T = 2(k-1) t$ | 在 PyTorch 的实现中，使用 Python 单进程，会有 GIL 锁，并不是真正的并发执行 | . PyTorch 在很早的版本引入了上述实现方式的 DataParallel，不过他们也意识到了这个版本的效率问题，所以后续版本中提出了一个效率更高的数据并行方法 DistributedDataParallel，同时在目前 PyTorch 1.8 版本中官方也更推荐使用 DistributedDataParallel 这种方式。 . DistributedDataParallel . DDP 是 DP 的升级版本，调用方式如下 . model = nn.DistirbutedDataParallel(model, device_ids=[rank]) . 他们大致原理是类似的，不过有很多细节上的区别，使得 DDP 效率更高，主要的区别如下： . 多进程 . 使用多进程支持真正的高并发，官方推荐做法是每张卡一个进程，从而避免单进程多线程的 GIL 问题，当然也支持多张卡在一个进程上，这样就和 DP 一样使用的多线程； . | 通信效率 . DP 的通信成本随 GPU 数量线性增加，而 DDP 使用 Ring AllReduce，保证通讯成本与 GPU 数量无关，能够扩展到大规模分布式训练中； . | 同步参数方式 . DP 通过收集梯度到 device[0]，在 device[0] 进行梯度更新，然后再将参数分发到其他所有设备上；DDP 则通过保证初始状态相同而且改变量也相同（同步梯度）的方式，保证模型同步和更新； . | . 下面我们重点讲一下 Ring Allreduce，这是效率提升的关键。 . Ring Allreduce . Ring Allreduce 原本是 HPC 领域一种比较成熟的通信算法，后被 Baidu SVAIL 引入到深度学习的训练当中，并与 2017年2月公开。 . 下面两张图直观的看到 allreduce 和 ring allreduce 之间的差别，allreduce 有一个中心参数服务器，而 ring allreduce 则像他的名字一样，构成了一个环。 . . . 下面我们具体来讲讲 ring allreduce 是如何进行梯度同步，从而保证总体同步和 GPU 数目无关。 . . 上面的动图展示了第一个成环的过程，每个 GPU 都接受来自另外上一个 GPU 的信息，同时发送给下一个 GPU，且每次发送的数据和 GPU 数量 k 成反比，即每张卡不会将这张卡上所有的数据都发给下一张卡，只会发 $ frac{1}{k}$ 的数据量。 . 在上面的例子中，一共有 5 个 GPU 参与通信，所以每次传递 $ frac{1}{5}$ 的数据量，第一次传递是从对角线开始，以第一份参数为例，在第一次传递中， GPU-0 将 $a_0$ 传递给 GPU-1，完成传递后， GPU-1 的第一份参数就变成了 $a_0 + a_1$ ，这时 GPU-1 在进行下一次传递，将 $a_0 + a_1$ 传递给 GPU-2，这样 GPU-2 的第一份参数就变成了 $a_0 + a_1 + a_2$ ，以此类推，通过 k-1 次传递之后，会获得下图的情况 . . 这时可以发现在每张 GPU 上都有一份参数是完整的，比如 GPU-0 上，第二份参数 $b_2 + b_1 + b_3 + b_4 + b_0$ 已经完整地收集到了所有卡上的数据，接着将上图橙色框的数据分别再做 k-1 次传递，最后就可以在每张卡上获得完整的数据信息。 . . 可以分析一下通信开销，假设有 k 个 GPU，传输总量是 p，b 为每次的通信上限，首先将梯度分为 k 份，每张卡每次传输 $ frac{p}{k}$ 的通信量，传递 k-1 次就可以分别在每张卡上收集到 $ frac{1}{k}$ 完整的数据，之后再传 k-1 次可以使得每张卡上获得完整的数据，所以总的通信开销是 . 2(k−1)pkb=2pbkk−12 (k-1) frac{ frac{p}{k}}{b} = frac{2 p}{b} frac{k}{k-1}2(k−1)bkp​​=b2p​k−1k​ . 所以整个式子在 k 很大的时候，和 k 是无关的，也证明了 ring allreduce 在通信上是和 GPU 数量无关的。 . Model Parallel . 上面讲的数据并行需要一张卡能够装下模型，当模型非常大，一张 GPU 无法放下模型的所有 tensor 时，就需要用到 model parallel，也叫做 tensor parallel。随着 GPT-3 等超级大模型的流行，未来模型越来越大也会是一个趋势，所以不要觉得一个模型需要用多张 GPU 来存放是一件离我们很遥远的事情。 . 说到模型并行，下面有一个简单的例子，这是从 pytorch forum 里面截取的，把模型的第一层 Linear 放到了 device[0] 上，第二层 Linear 放到了 device[1] 上，那么这个能被成为模型并行吗？ . class ToyModel(nn.Module): def __init__(self): super(ToyModel, self).__init__() self.net1 = torch.nn.Linear(10, 10).to(&#39;cuda:0&#39;) self.relu = torch.nn.ReLU() self.net2 = torch.nn.Linear(10, 5).to(&#39;cuda:1&#39;) def forward(self, x): x = self.relu(self.net1(x.to(&#39;cuda:0&#39;))) return self.net2(x.to(&#39;cuda:1&#39;)) . 其实从严格意义上来讲，这个并不能称为模型并行，只是把同一个模型的不同层 split 到不同的 device 上，真正的模型并行还需要是的他们能够同步执行 (concurrently)，但是上面的例子中，两个 Linear 并不能同时计算，第二个 Linear 需要获取第一个 Linear 的输出才能进行计算。 . 那么如何能够写一个简单的模型并行例子呢？在 PyTorch model parallel tutorial 中，给出了一个简单的例子。 . 得益于 PyTorch 使用的 CUDA operations 是异步的，所以可以用下面的方式来轻松构建一个模型并行的操作，而不需要使用到多线程或是多进程。 . class PipelineParallelResNet50(ModelParallelResNet50): def __init__(self, split_size=20, *args, **kwargs): super(PipelineParallelResNet50, self).__init__(*args, **kwargs) self.split_size = split_size def forward(self, x): splits = iter(x.split(self.split_size, dim=0)) s_next = next(splits) s_prev = self.seq1(s_next).to(&#39;cuda:1&#39;) ret = [] for s_next in splits: # A. s_prev runs on cuda:1 s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) # B. s_next runs on cuda:0, which can run concurrently with A s_prev = self.seq1(s_next).to(&#39;cuda:1&#39;) s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) return torch.cat(ret) . 在上面的例子中，首先提前在 device[0] 做一次计算，然后将结果 copy 到 device[1] 上，接着在进行后续的计算。后续是一个 for loop，代码顺序是先执行 device[1] 上运算 A，不过因为 CUDA 的异步特性，这个计算 A 并不会马上执行，随后代码上再执行 device[0] 上的计算 B，这时两个操作 A 和 B 会一起进行计算。等待 B 计算完毕后，会再次实现和之前一样的操作，将 tensor 从 device[0] 上 copy 到 device[1] 上，因为在 cuda 上 device-to-device 的操作会在当前 streams 上进行同步，而上面的实现在 device[0] 和 device[1] 上都使用的是默认的 streams，所以不需要额外进行同步。 . 其实在上面的实现中，使用了流水并行的技巧，后面我们会更详细的讲解。 . Partial-FC . 最后我们以人脸识别为模型并行的一个经典例子，介绍其中应用非常广泛的 FC 并行以及他的一种变种 Partial-FC。 . Partial FC: Training 10 Million Identities on a Single Machine . 上面是人脸识别中模型并行的经典图示，在 Backbone 部分做数据并行，在 FC 部分做模型并行，比如一共有 C 个 ID，k 张 GPU，那么每个 GPU 上会放 $ frac{C}{k}$ 类别中心。 . 整体的计算过程如下： . 将数据分到不同的卡上，在 backbone 上并行做前向计算得到 features X； | 每张卡上都同步其他所有卡的 features，然后在每张卡上并行计算对应类别中心的 logits； | 每张卡上同步其他卡上的 logits 结果，并行计算 loss 以及 logits 对应的梯度； | 在每张卡上并行计算各自类别中心权重 $w_i$ 对应的梯度 $ nabla w_i$ 和 feature X 对应的梯度 $ nabla X$； | 同步其他所有卡的 $ nabla X$ ，获得平均梯度，然后将其 scatter 到各自对应的卡上，并行做自动求导，获得 backbone 的梯度； | 以上过程就是人脸识别中标准的 FC 并行框架，不过这种方式的并行会出现一些显存问题，我们可以看看下面的公式 . Memw=d×C↑k↑×4 bytesMemlogits=Nk×Ck×4 bytesMem_w = d times frac{C uparrow}{k uparrow} times 4 bytes Mem_{logits} = N k times frac{C}{k} times 4 bytesMemw​=d×k↑C↑​×4 bytesMemlogits​=Nk×kC​×4 bytes . 上面分别表示每个 GPU 上权重 w 的显存和计算 logits 的显存，其中 d 表示 feature 维度，C 是类别数目，k 是 GPU 数量，N 是 mini-batch size，4 bytes 表示用 float32 进行计算。 . 通过上面的计算公式可以看出，如果增加一倍 ID 规模，那么可以通过增加一倍的 GPU 数量 k 来保证每张卡上的显存占用量一致，不过通过观察 logits 的显存占用量就会发现，如果不断地增加 GPU 数量 k，会导致 logits 的显存占用量线性增长，所以随着 ID 规模的增加，不断增加 GPU 数目最终会导致显存爆炸。 . Partial-FC 提供了一个非常简单的思路来解决这个问题，既然 logits 显存会随着 GPU 数量一直增加，那么减少 logits 的显存就可以了。接着通过实验发现采样部分负样本和全部负样本最后的收敛效果几乎一致，所以在 Partial-FC 中，每次计算 logits 并不会使用 w 中的全部负样本，只会采样固定比例的负样本，最终可以使得计算的 logits 显存以固定比例降低。 . Pipeline Parallelism . 最后讲一下流水并行，当模型非常巨大，需要用多张 GPU 进行存储的时候，就需要用到流水并行。流水线并行算是广义模型并行的一种特例，通过多个设备来共同分担显存消耗，同时只在相邻的设备之间进行通讯，因此通信张量较小。 . GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism . 上图中 (a) 展示了流水并行的前向反向计算流，(b) 表示一种 naive pipeline parallelism，同步更新和串行计算，后一个设备依赖上一个设备的结果，所以每次都只有一个设备在计算，其他设备在等待，没有发挥分布式的优势。 . (c) 是 GPipe 这篇论文提出了一个解决方案，将一个 mini-batch 切分成多个更小的 micro-batch，实现不同的 GPU 并行同步计算，每个 micro-batch 反向计算获得的梯度进行累加，在最后一个 micro-batch 累加结束之后，再统一更新模型。有兴趣的同学可以直接去看 GPipe 这篇论文。 . 混合并行 . https://www.deepspeed.ai/tutorials/pipeline/ . 上面讲了多种并行方式一般会混合使用，当多种并行同时使用的时候，也叫做混合并行。上面是从微软发布的 DeepSpeed 的 tutorial 贴出一个例子，主要使用了数据并行 + 流水并行，GPU-0 和 GPU-2 作为 Group-1，GPU-1 和 GPU-3 作为 Group-2，Group-1 和 Group-2 进行数据并行，而在每个 Group 内部进行流水并行，将 Group 内的 batch 数据切分成 4 个 micro-batch。另外 Deep Speed 还提供了一些其他的 features，比如 ZeRO 可以降低内存开销，训练更大的模型，有兴趣的同学可以自行查看。 . Further Reading . 分布式并行是深度学习中的一个重要的问题，随着数据，算力和模型的规模都越来越大，如何高效、稳定地训练模型也变得越来越重要，上面介绍的并行只是一个入门的内容，有兴趣的同学可以看看这篇 oneflow 的文章 OneFlow —— 让每一位算法工程师都有能力训练 GPT，用 GPT-3 作为例子介绍了分布式训练模型的一些最新的技术。 . Reference . PyTorch 源码解读之 DP &amp; DDP：模型并行和分布式训练解析 | https://d2l.ai/chapter_computational-performance/parameterserver.html | Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU &amp; Distributed setups | Visual intuition on ring-Allreduce for distributed Deep Learning | Bringing HPC Techniques to Deep Learning | 单机多卡的正确打开方式（一）：理论基础 | Partial FC: Training 10 Million Identities on a Single Machine | PyTorch tutorial | GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism | Deep Speed | OneFlow —— 让每一位算法工程师都有能力训练 GPT | .",
            "url": "https://l1aoxingyu.github.io/blogpages/summary/self-supervised%20learning/2021/05/16/dl-dist-train.html",
            "relUrl": "/summary/self-supervised%20learning/2021/05/16/dl-dist-train.html",
            "date": " • May 16, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Study Less, Study Smart",
            "content": "学习变得越来越重要，甚至在很多领域需要终生学习，能否高效学习决定了人与人之间的差距。在这篇文章中，我将分享给大家一些高效学习的技巧和建议，帮助大家快速而高效地学习新知识。 . . 为什么需要终生学习 . 一提到学习，可能大家的脑子里面会回想起高中或者大学时的情景，每天日以继夜，为了考试努力学习。好不容易终于熬完了大学，以为之后的人生中再也不会有”学习“了，如果你这样想，那么就大错特错了。 . 如果你是一个对自我要求很高的人，期望不断学习来提升自己，同时也希望能够成为同龄人中的佼佼者，那么终生学习对你而言是毫无疑问的事情，你需用一直努力才能保持竞争力。 | 如果你说我只希望躺平，做一个打工人，满足于普通的人生，那么是不是就不需要学习了呢？现在社会发展的速度越来越快，不需要动脑子的工作慢慢会被人工智能替代，而需要动脑子的工作会出现很多新的概念和内容，如果不持续的学习，根本无法完成正常的工作。所以仅仅是持有不被社会淘汰的标准，也需要不断地学习。 | 所以不管是对于自我要求很高的人，还是希望仅仅跟上社会发展脚步的人来说，终身学习都变得越来越必要。工欲善其事必先利其器，学习”如何学习“可以帮助我们在遇到新的概念和问题的时候更加游刃有余，使用更少的时间掌握更多的内容。 . 如何高效地学习 . 无意间看到了Marty Lobdell 在 Youtube 的视频 Study Less Study Smart 后，非常遗憾自己没能在更早的时候就看到，在这里强烈推荐给大家。 . 在视频中，Marty 列出了影响学习效率的几个因素，同时配合相关的案例讲解，下面列举一些我认为比较重要的观点，更详细的内容建议大家直接食用原始视频，效果更佳。 . 番茄工作法 . 番茄工作法是一种时间管理技巧，相信很多人都有一定的了解，简单来说就是使用一个定时器来分割出一个一般为25分钟的工作时间和5分钟的休息时间，这个时间段被称为一个番茄钟。 . 番茄工作法的发明者使用这种方法来对抗拖延症，因为每个番茄钟只有一小段时间，比较容易开始。所以可以逼迫自己先开始一个番茄钟，而人往往在开始进行执行任务之后，更容易坚持下去，这样就能够开始做任务从而避免拖延症。 . 现在大家对番茄工作法的评价褒贬不一，有的人认为将一段工作划分成小的时间段会破坏工作的完整性，比如对于创作或者编程这样的任务，需要长时间的专注，如果切割成了很多小块的时间，那么很可能刚刚进入状态，一个番茄工作时就结束了，被迫退出这种状态。 . Marty 在视频中表示，人在长时间学习时，精力高度集中，如果长时间保持这种状态，效率会随着时间越来越低。这个时候如果强迫自己继续坚持学习或工作，反而效果会越来越差，但是如果休息一小段时间，比如5分钟，这是精力会重新充电，这时再继续学习可以获得更好的效果。 . 我个人认为在学习或者工作一段时间之后休息是很有必要的，一小段时间的休息之后再重新开始工作可以获得更好的效果。但是考虑到有一些工作可能需要较长的启动时间，所以可以根据个人需求和任务类型进行番茄钟时长的自定义，比如进行编程或者写作等任务时，可以将工作时长设定为50分钟而非25分钟，或是在番茄钟响后并不进入休息，继续工作直到感觉累了，再进行休息。 . 建立自己的学习区 . 大多数人都没有自己专属的学习区，要不在客厅学习，要不在床上看书，这样其实不利于构建一个良好的学习环境。每个房间和区域都有自己的意义，比如客厅是大家娱乐和社交的场所，卧室和床是休息的地方，如果在这些地方学习，潜意识里并不会认为你是真正在学习，所以很难进入学习状态。 . 如果建立一个专属的学习区，每次来到这个区域就开始学习，久而久之会在大脑深处构建一种暗示效果，当下次开始学习的时候，直接来到学习区，这样可以更快地进入状态。书房是一个非常好的学习区，不过并不是每个人家里都有书房这个条件，所以很多人去学校，图书馆或者咖啡厅进行学习和阅读。 . 如果你不想去外面，就想在家里学习，但是家里又没有书房，Marty 还提供了一个低成本的方式来构建自己的学习区，那就是使用一盏台灯。每次要要学习的时候，就打开特定的台灯，当学习结束之后再关闭台灯，通过这样简单的步骤构建一个学习空间，虽然并没有在物理意义上开辟新的空间，但是可以给大脑一种心理暗示，可以让大脑将这种灯光和学习工作关联起来，这样有利于快速进入学习状态。 . 专注力 . 很多人喜欢在学习的时候听音乐或者是看电影，认为这种事情不会耗费注意力。其实人是一个单线程生物，我们的注意力用于只能聚焦在一件事情上，当你在学习是听音乐，有一部分的注意力会在你不经意间分散到音乐和歌词上，从而降低学习效率。 . 所以记得每次专注于一件事儿上，如果实在想听音乐，可以听一些白噪音，这样有助于提升学习效率，但是一定不要听歌或者是看电影。 . 发现事实背后的概念 . 很多时候教材为了方便概念的讲解，会使用隐喻和类比的方式进行举例，或者是讲一些概念的实际用途。这个时候不要去记住这些事实，而是要理解和记住事实背后的概念，概念就是指它的原理，功能以及它和其他的概念如何进行联系。一旦记住这个概念，那么你将一辈子都不会忘记，而相关的事实可以通过 Google 和网络进行搜索。 . 首先需要具备区分事实和概念的能力，同时寻找事实背后的概念往往需要进行总结和归纳，找到事实背后的本质，这些能力都需要不断训练才能获得。 . 费曼技巧 . 理查德·费曼是理论物理学家，不过它广为人知的便是“费曼学习法”。 . 简要来说，“费曼学习法”分为4步： . 选定一个学习的内容，这个内容可以是任何你当下想学习的知识，然后通过各种资料进行学习； | 想另外一个人教授你所学习的内容，或者是在一张白纸上想象你正在向别人教授这个内容，简单来说就是知识的输出； | 在教授过程中，发现自己“卡壳”以及解释不清的内容，这就是自己的薄弱点，返工学习和纠错，然后再次进行教授和输出，直到可以清晰地表达相关的知识； | 回顾和精简，努力简化表达，将所学的知识进行内化； | 学习金字塔是美国国家训练实验室研究的成果，从下面的金字塔中，也能看出“费曼学习法”位于主动学习中的最高层，可以最大程度地留存学习的知识。 . . 在 Marty 的视频中，通过几点不同的描述来联合构成了费曼技巧：1. 使用自己的话对概念进行解释；2. 关上书回忆学习的内容而非仅仅打开书辨认知识点；3. 教授给另外一个人所学的内容，如果没有其他人可以试着交给一张椅子或者在一张白纸上写下来。 . 找到一个学习小组 . 除了自己独立学习之外，也可以尝试组建一个学习小组共同学习，不仅可以互相帮助解答疑问，同时也可以互相激励。同时也可以在学习小组的成员中进行费曼技巧，以及互相分享学习方法。 . 充足的睡眠 . 充足的睡眠在 Marty 看来是一个“命令”而非“建议”。睡眠的影响也是一直以来我所忽略的内容，我们往往到了该睡觉的时候想着再多看几页书，或者是多看几分钟视频，从而导致晚睡，这样往往是舍本逐末。 . 在视频中，Marty 强调好的睡眠不仅仅对身体健康有益处，同时也有利于帮助大脑巩固长期记忆的知识点成为永久记忆的知识点。看到这里我突然想起了之前高中为了刷题总是熬夜到晚上2点，如果能够更早看到这个视频，可能我会早早地“放过”自己，让自己11点半就进入睡眠，或许能够获得一个更好的成绩。 . SQ3R 方法 . SQ3R 是 Survey, Question, Read, Recite and Review 5 个单词的缩写，这是一种学习教科书的方法。首先明确教科书并不是小说，跳着读并不会影响学习效果，可以直接跳到需要学习的页面。 . SQ3R 可以简要描述为下面的步骤： . 简要浏览一下需要学习的主题，看看相关的插图等等 (Review)； | 寻找这一章的主要希望解决的主要问题是什么，记住并写下他们，时刻在心里提醒自己 (Question)； | 阅读教材中的粗体字，比如题目，副标题，被标粗的部分等等，因为这些内容是作者想强调的。接着如果有很长的段落，读这些段落的第一个句子和最后一个句子。然后再读教材中的所有内容，同时尝试回答之前提出的主要问题，如果不能回答，那么重新读这些内容，不过这一次用记号笔标记一些你认为重要的内容，同时在每一页的边缘做笔记，直到完成问题的回答 (Read)； | 列出下一个希望回答的问题，然后重复上面的3步； | 使用费曼技巧将你希望解释的内容和问题重新用自己的话来描述，确保使用一个6岁孩子也能听懂的语言；除此之外，也可以假装是这个领域的专家，写出相关的文章，如果你发现你不能很好的解释和概括其中的内容，回到材料中重新学习 (Recite)； | 如果你完成了上面的步骤，那么你会获得3个材料：a）一本有标注和笔记的教材；b）这个话题主要的问题以及答案；c）一篇相关的文章或者是思维导图。接着需要记得定期复习相关的内容，形成长期记忆 (Review)； | 结语 . 上面的内容就是我在学习 Marty 视频后总结的几个我认为比较重要的学习技巧，同时我正在看 Coursera 相关的课程 Learning How to Learn: Powerful mental tools to help you master tough subjects，如果后续学习完这个课程，会在写一篇文章进行介绍。 . 最后希望大家能够从这篇文章中得到一些收获，也强烈推荐大家去看 Marty 的原版视频，最后欢迎大家在评论中提供自己比较高效的学习技巧。 .",
            "url": "https://l1aoxingyu.github.io/blogpages/utility/2021/05/09/Study-Less-Study-Smart.html",
            "relUrl": "/utility/2021/05/09/Study-Less-Study-Smart.html",
            "date": " • May 9, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "FastReID V1.0: Beyond reID",
            "content": "引言 . FastReID 自20年6月发布以来，我们收到了很多用户的反馈，当初的 v0.1 版本存在大量需要优化的部分，经过了最近半年的持续优化，终于在 21年1月14日，我们低调地发布了 FastReID V1.0，这次更新包括非常多的方面，但是最大的贡献在于我们将 FastReID 扩展到了更多的任务上，同时在这些任务上都达到了 SOTA 结果。 . tldr: 我们更新了 FastReID V1.0 版本，不仅实现了更快的分布式训练和测试，模型一键导出 caffe/onnx/tensorRT，还实现了蒸馏，自动超参搜索以及更多任务的扩展，比如人脸识别，细粒度检索等等，最后基于 FastReID 我们拿到了深圳 NAIC20 ReID track 的第一名。 . 下面简单介绍一下 FastReID V1.0 的各项改进。 . . Embedding 知识蒸馏 . 深度神经网络一般有较多的冗余，同时模型太大会导致 inference 时间变长，所以在部署的时候需要考虑对模型进行压缩，减小其参数量，其中有较多的压缩方式，比如剪枝，量化和蒸馏等。 其中蒸馏是一种比较流行的范式，可以保证模型不需要进行结构修改的情况下，得到较大的性能提升，所以我们选择在 FastReID 中加入蒸馏的支持，可以让我们用小模型部署的时候获得更大的精度提升。 . 虽然蒸馏发展了这么多年，但是通过尝试我们发现 Hinton 的 Distilling the Knowledge in a Neural Network 还是最 solid 的选择。 同时我们将原本的蒸馏 loss 优化为具有对称性的 JS Div loss，最后修改蒸馏的 soft label 生成方式。 . 不同于 softmax 分类 loss，在 embedding 任务中通常会使用效果更好的 margin-based softmax，比如 arcface 等等， 这时直接使用基于 margin 的 logits 生成 soft label 效果很不好，所以我们将 soft label 修改为去掉 margin 的 logits 输出。 . 除了可以对 label 进行蒸馏之外，也可以对 feature 进行蒸馏，通过实验了一大堆不 work 的特征蒸馏方法之后，我们发现 overhaul-distillation 可以在 loss 蒸馏的基础上进一步对网络进行提升，所以也将这个方法加入到了 FastReID 当中，但是由于 overhaul 需要对 backbone 进行一些修改，获得 relu 之前的 feature，所以我们选择构建了一个新的 project 而不是直接去 FastReID 里面修改 backbone。 . 最后我们在 dukeMTMC 上进行实验，使用 r101_ibn 作为 teacher model, r34 作为 student model，可以获得如下的效果提升。 . DukeMTMC-reid . Model Rank@1 mAP . R101_ibn (teacher) | 90.66 | 81.14 | . R34 (student) | 86.31 | 73.28 | . JS Div | 88.60 | 77.80 | . JS Div + Overhaul | 88.60 | 78.25 | . 蒸馏的使用也非常简单，只需要首先按照正常的方式训练一个 teacher model，如果只想使用 loss 蒸馏，可以使用 Distiller 作为 meta_arch，如果希望加上 overhaul，只需要使用 DistillerOverhaul 作为 meta_arch 就可以了。 最后再指定 teacher model 的配置文件和训好的 weights 就可以了。 . 下面用 R101_ibn 作为 teacher model，R34 作为 student model 举一个例子 . # teacher model training python3 projects/FastDistill/train_net.py --config-file projects/FastDistill/configs/sbs_r101ibn.yml --num-gpus 4 # loss distillation python3 projects/FastDistill/train_net.py --config-file projects/FastDistill/configs/kd-sbs_r101ibn-sbs_r34.yaml --num-gpus 4 MODEL.META_ARCHITECTURE Distiller KD.MODEL_CONFIG projects/FastDistill/logs/dukemtmc/r101_ibn/config.yaml KD.MODEL_WEIGHTS projects/FastDistill/logs/dukemtmc/r101_ibn/model_best.pth # loss+overhaul distillation python3 projects/FastDistill/train_net.py --config-file projects/FastDistill/configs/kd-sbs_r101ibn-sbs_r34.yaml --num-gpus 4 MODEL.META_ARCHITECTURE DistillerOverhaul KD.MODEL_CONFIG projects/FastDistill/logs/dukemtmc/r101_ibn/config.yaml KD.MODEL_WEIGHTS projects/FastDistill/logs/dukemtmc/r101_ibn/model_best.pth . 自动超参搜索 . 炼丹一直困扰着各位调参侠，特别是每次到了一个新的场景，就需要重新调参来适应新的数据分布，非常浪费时间。 所以我们决定在 FastReID 中加入了自动超参搜索的功能来解放各位调参侠的双手，让大家可以更好的划水。 . 通过一系列调研，最后决定使用 ray[tune] 这个超参搜索的库，在集成到 FastReID 中间也遇到了非常多的坑，最后我们成功地在 FastReID 中实现了超参搜索的功能。 . 使用方式非常简单，如果你想用 Bayesian 超参搜索跑 12 组试验，可以使用下面的代码就可以开始自动分布式训练，如果有4张卡，那么可以4个试验同步一起跑 . python3 projects/FastTune/tune_net.py --config-file projects/FastTune/configs/search_trial.yml --num-trials 12 --srch-alog &quot;bohb&quot; . 另外需要搜索的超参空间需要在 projects/FastTune/tune_net.py 中进行配置，更具体的使用方式可以参考 tutorial。 . 唯一不足的是还不能用pytorch的分布式数据并行，后续有时间会进一步优化，希望这能够成为大家打比赛刷分，做业务的利器。 . 最多最全的任务支持 . 我们刚刚发布 FastReID v0.1 时，他只是作为一个重识别的 toolbox，支持重识别的业务模型和 research。 . 后面考虑到各种识别任务的模型结构都长得差不多，所以我们希望 FastReID 只需要稍微 customize 就能够支持各种不同的任务。 . 但是每种任务都有自己的一些特殊性，把这些特殊性全部往 FastReID 里面塞肯定是不现实的，为了不引入冗余性，我们通过对每种 task 单独构建 project 的方式对 FastReID 进行扩展，同时也相当于提供了一些扩展任务的参考写法和 example，毕竟我们的文档一直没有时间写(逃~)。 . 最后呈现在 FastReID 的 projects 中一共可以支持 image classification (FastClas), attribute recognition (FastAttr), face recognition (FastFace) 和 fine-grained image retrieval (FastRetri) 4 种比较常见的识别任务，同时我们也分别跑了几个 benchmark 以保证代码的实现是正确的。 . . . 同时大家在 customize 自己的 project 时，也可以将这些 projects 中的东西进行排列组合来实现新的功能，比如将 FastDistill 和 FastFace 组合在一起，就可以实现人脸识别中的模型蒸馏。 . NAIC20 reID 比赛 . 借助 FastReID 高效的分布式训练模式和超参搜索等功能，我们拿到了 naic20 比赛的第一名，比赛方案也开源在 FastReID 的 projects/NAIC20 中。 一些比赛中的 tricks 已经直接集成到了 FastReID 中，有空再专门写一下比赛的方案吧，总结起来就是大模型+大 input size + ensemble。 . 总结 . 一套好的 codebase 对于大家做实验和做业务都起着事半功倍的效果，大家也越来越发现代码的工程质量不仅影响业务模型的研发效率和性能，同时还对研究工作有着影响。 . FastReID 不仅仅希望能给 ReID 社区提供稳定高效的代码实现，同时也希望大家能够基于 FastReID 去做算法研究，同时扩展到更多其他任务上。 . 也希望大家能够踊跃地在 GitHub 上提 issue 和 PR，让我们一起把 FastReID 越做越好。 . 在此感谢 JD AI 组的同事和老师的支持，正是因为大家的努力让 FastReID 变得更好，并且科研项目也都在 FastReID 上取得了更好的性能。 . Reference . FastReID: A Pytorch Toolbox for General Instance Re-identification, He, Lingxiao and Liao, Xingyu and Liu, Wu and Liu, Xinchen and Cheng, Peng and Mei, Tao, arXiv preprint arXiv:2006.02631, 2020 . | Deep spatial feature reconstruction for partial person re-identification: Alignment-free approach, He, Lingxiao and Liang, Jian and Li, Haiqing and Sun, Zhenan, CVPR2018 . | Foreground-aware Pyramid Reconstruction for Alignment-free Occluded Person Re-identification, He, Lingxiao and Wang, Yinggang and Liu, Wu and Zhao, He and Sun, Zhenan and Feng, Jiashi, ICCV2019 . | Black Re-ID: A Head-shoulder Descriptor for the Challenging Problem of Person Re-Identification, Boqiang, Xu and Lingxiao, He and Xingyu, Liao and Wu,Liu and Zhenan, Sun and Tao, Mei, ACM MM2020 . | A Comprehensive Overhaul of Feature Distillation, Heo, Byeongho and Kim, Jeesoo and Yun, Sangdoo and Park, Hyojin and Kwak, Nojun and Choi, Jin Young . | Distilling the Knowledge in a Neural Network, Geoffrey Hinton, Oriol Vinyals, Jeff Dean . | Tune: A Research Platform for Distributed Model Selection and Training, Liaw, Richard and Liang, Eric and Nishihara, Robert and Moritz, Philipp and Gonzalez, Joseph E and Stoica, Ion . | ArcFace: Additive Angular Margin Loss for Deep Face Recognition, Jiankang Deng, Jia Guo, Niannan Xue, Stefanos Zafeiriou . | PaddleClas: https://github.com/PaddlePaddle/PaddleClas . | .",
            "url": "https://l1aoxingyu.github.io/blogpages/reid/fastreid/2021/04/28/fastreid-v1.html",
            "relUrl": "/reid/fastreid/2021/04/28/fastreid-v1.html",
            "date": " • Apr 28, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "FastReID: 一个面向学术界和工业界的 ReID Toolbox",
            "content": "引言 . FastReID 平台已经成为京东人工智能研究（JD AI Research）的开源项目之一，它是面向学术界和工业界的研究/开源项目，主要用于研究和应用落地。 先放上 Github 链接： . fast-reid . 我们的 FastReID 也有一篇 paper 进行更加详细地介绍，如果想要了解更多关于 FastReID 的信息，可以直接去看原始 paper。 . FastReID: A Pytorch Toolbox for Real-world Person Re-identification . 接下来会分享开发 FastReID 初衷以及 FastReID 的特点。 . 动机 . 最早的时候和罗博(@罗浩)搞了一个 reid strong baseline，不过那个项目在 pytorch 的基础上，又用 ignite 包了一下，开源之后很多人都说 ignite 比较影响使用体验，所以后面在我自己维护的 baseline 版本里面就去掉了 ignite。 . 我们自己做项目，以及实习生做研究都是基于 strong baseline 去魔改的，后面发现各自搞的 project 和原始的 baseline 差别越来越大，导致我们想要在实际场景中运用研究工作时效果不好，遇到了很多代码不对齐的现象。出现这个问题原因在于其中一个同学修改了某一个训练逻辑或者预处理的地方，他自己忘记了，最终发现把模型合并在一起的效果总是不好，需要花很多时间去解决这些琐碎的问题。 . 正是由于这个原因，我们决定把 baseline 这套框架封成一个库，大家基于这套库去做工作就更利于找到各自定制化的地方。开源社区中也有几个比较流行的 reid 库，比如 torchreid，Person_reID_baseline_pytorch 等等，都是很好的库，值得我们去学习。最近 Facebook AI Researck 开源了 Detectron2 项目，它里面的整体概念和设计哲学都非常棒，所以我们决定参考 detectron2 的设计来整个 FastReID 架构。 基于 FastReID，我们的产品模型和 research 的模型有了比较好的兼容性，同时也比较容易去 customize 一些功能，模块化的设计允许研究人员能自定义地插入自己想要的模块。 . 我们构建 FastReID 的目的在于满足 JD AI Research 的研究需求，能够快速地准备地实现一些 ideas，并且能够将研究员的研究成果快速地部署到实践中。 无论在学术界还是工业界，开源项目都有助于整个社区的快速发展，使我们的想法快速付诸于实际落地项目中。我们也希望 FastReID 的发布能够继续加速行人重识别领域的发展。 . 一些新特性 . FastReID 采用高度模块化设计，它具有更高的灵活性和可扩展性，能够在支持多 GPU 训练，它的扩展性设计使其在重构代码的情况快速实现很多研究项目。 . 下面我们介绍一下其中的一些新特性。 . 1.基于 FastReID，我们在多个 ReID 任务都获得非常不错的性能，并且用于业务线中，包括行人 ReID、Occluded/Partial 行人 ReID、跨域行人 ReID 和车辆 ReID。 . 虽然在 ReID 发展的这几年里面，有了很多 ReID 的 paper，大家的刷的点也越来越高了，但是性能好且稳定的方法其实还是基于最简单的 global feature 和分块的 local feature，其他使用额外信息如 pose，mask，parsing 之类的方法在实际使用中都不够稳定，同时也比较笨重。 . 所以我们在 toolbox 中内置了这两种方法，一种是基于 global feature 的 strong baseline，一种是基于分块的 MGN。 然后在 BagofTricks 的基础上，将其他可能有用的 tricks 都实现了一下，包括有效的，比如 circle loss，gem pooling 之类的，也有没有效果的，比如 SWA, AugMix 等等。 最终基于 ResNet50-ibn backbone，在三个数据库上实现了下面的性能 . Method Market1501 DukeMTMC MSMT17 .   | Rank@1 (mAP) | Rank@1 (mAP) | Rank@1 (mAP) | . BagTricks | 94.4% (86.1%) | 87.1% (76.9%) | 72.3% (48.3%) | . FastReID-baseline | 95.7% (89.3%) | 91.3% (81.6%) | 84.0% (61.2%) | . FastReID-MGN | 95.8% (89.7%) | 91.6% (82.1%) | 85.1% (65.4%) | . 在 Marekt1501 上面提升空间已经不大了，因为后面有一些错误标签，但是在 DukeMTMC 和 MSMT17 上还是有比较显著的提升，详情可以去 model zoo 里面查看完整的配置文件。 . 在 partial re-id 上，我们也基于之前 DSR 的工作，在三个 partial 库上有了持续的提升 . Method PartialReID OccludedReID PartialiLIDS .   | Rank@1 (mAP) | Rank@1 (mAP) | Rank@1 (mAP) | . FPR | 81.0% (76.6%) | 78.3% (68.0%) | 68.1% (61.8%) | . FastReID-DSR | 82.7% (76.8%) | 81.6% (70.9%) | 73.1% (79.8%) | . 具体可以去 projects/PartialReID 中查看代码和训练配置。 . 在 cross-domain reid 上面，我们也做了一些工作，正在投稿中，之后会在开源在projects/Cross-domain-reid 中，从效果上看，在跨域上已经大大缩小了和有监督 reid 的差距。 . Method Market1501 to DukeMTMC DukeMTMC to Market1501 .   | Rank@1 (mAP) | Rank@1 (mAP) | . DirectTransfer | 54.4% (34.0%) | 62.6% (32.1%) | . Our method | 82.7% (69.2%) | 92.7% (80.5%) | . 在实际场景中我们发现穿黑衣服的人是一个比较难的问题，所以我们也基于 FastReID 构建了头肩模块去解决黑衣人的问题，也实现了比较不错的性能提升，paper 正在投稿，后面会开源在 projects/HAA 中。 . Method Black-ReID .   | Rank@1 (mAP) | . Baseline(R50) | 80.9% (70.8%) | . HAA(R50) | 86.7% (79.0%) | . 在 vehicle re-id 上，我们也在 VeRI 数据集上跑了一下 baseline，得到了一个比较不错的结果，另外两个数据集 VehicleID 和 VERI-Wild 上也跑了一下，具体可以去 model zoo 里面查看。 . Method VeRi .   | Rank@1 (mAP) | . FastReID-baseline | 97.0% (81.9%) | . 另外还有一些基于 FastReID 做的工作都在投稿中，就不详细介绍了，后续都会开源在 fast-reid/projects 里面。 . 2.在模型评估上我们实现了更多的功能，比如我们支持比较灵活的测试方式，通过下面的命令可以实现在 Market1501 和 MSMT17 上联合训练，然后在 Market1501 和 DukeMTMC 上进行测试。 . DATASETS: NAMES: (&quot;Market1501&quot;, &quot;MSMT17&quot;,) TESTS: (&quot;Market1501&quot;, &quot;DukeMTMC&quot;,) . 另外也提供了更加丰富的指标评估，除了 reid 中最为常见的 CMC 和 mAP，以及在 reid-survey 中提出的 mINP之外，我们还提供了 ROC 曲线和分布图 . 因为我们发现在实际业务场景中往往是开集测试，甚至 gallery 都是在动态变化的，在这种情况下通过单一的 rank1 或者是 mAP 来评估模型就不那么准确了，在实际应用时往往需要卡阈值再出 topK，所以通过分布和 ROC 曲线可以更好地帮我们找到阈值。 . 除了评估指标，可视化其实非常重要，通过可视化 rank list 可以快速定位模型的问题，同时也会发现一些错误标注，比如通过可视化我们发现 Market1501 里面有一些错误标注，最高的 rank@1 就只能做到 96 左右，而一些公司的 PR 文可以做到 99，我也不知道他们是怎么做到把标注错误都搞定的 😂。 . 我们发现很多库都只是实现了最基本的可视化功能，比如可视化 rank list，但是这种单一的可视化其实并不能帮助我们从多个维度了解问题，所以我们实现了更好的可视化功能。首先可以根据每个 query 的 AP 进行排序展示，比如 AP 从小到大进行展示，那么可视化出来的第一张图片就是 AP 最低的 query，通过这个方式我们可以了解到模型处理能力最差的 bad case。 . 另外我们在看预测结果的时候，其实也会想知道到底这个 query 的标注是怎么样的图片，比如我们再看 duke 数据集中下面的 rank list 时，发现他的 AP 是0，下面的蓝色框表示都是错误的匹配。 . 这时我们就会疑惑，到底这张 query 的标注长什么样，这时如果我们像下面这样将 label 同时可视化出来，我们就可以快速地知道，原来 query 其实是黄衣服后面那个黑衣服的人，因为是用 tracking 算法标注的，他大部分都被前面穿黄衣服的人挡住了，所以模型无法找对，而且这种情况下搞模型结构很难解决的，在实际业务中直接从源头上选择质量好的 query 是一个更好的解决方案。 . 3.大多数的库都只关注学术界做 research，我们更希望能够产学研结合，research 中 work 的东西能够快速到实际场景中去验证效果，发现实际中真正需要解决的问题。 当然在实际研究中可以天马行空去写代码，但是这份代码无法快速地在实际场景中去验证，如果基于 FastReID 去重构和开发，那么我们就能够找到新方法所需要的最小代码实现，就能够很轻易地移植到实际业务中，也不用把大量的时间花在对齐训练逻辑以及预处理上了。 . 另外就是如何将 pytorch 训练的模型更容易地部署到生产环境上，这也是工业界比较关心的事情，python 写的模型如果没有优化和加速的话，在实际中是很慢的。 为了更好地在工业界中应用，我们会在 FastReID 中加上一些脚本能够容易地将 pytorch 训练的模型转到 caffe 和 TensorRT 上，最后做一下模型的量化。目前 pytorch 升级到 1.3 之后慢慢开始支持量化了，我们也会尝试在 pytorch 端直接做量化，和蒸馏小模型。不过这些部分的内容还在整理和开发中，目前还没有 ready。 . 未来的一些改进方向 . 上面说了 FastReID 中的一些新特性，同时还有一些地方需要继续改进。 . 目前的多卡训练还是基于 DataParallel 来实现的，会存在负载不均衡，速度损失以及无法实现多机的缺点，我们正在用 DistributedDataParallel 来替换 DataParallel。 | 模型转换，量化和蒸馏小模型等部分的代码还没有搞定，后续会慢慢开源一部分。 | 可能会考虑将 FastReID 推广到通用的 image retrieval 上。 | 结语 . 科技的进步是整个社区的努力，包括学术界和工业界。 个人的努力永远赶不上整个社区的努力，这也是开源 FastReID 的初衷。 我们一直主张共享代码，快速试验新的想法，通过 FastReID 的发布加速整个 ReID 的产业化落地。 我们也会继续发展和完善FastReID。希望大家能够 star/fork/watch/pr，大家互相学习，共同推动计算机视觉的发展。 . 在此感谢 JD AI 组的同事和老师的支持，正是因为大家的努力让 FastReID 变得更好，并且科研项目也都在 FastReID 上取得了很好的性能。 . . [1] Luo, Hao and Gu, Youzhi and Liao, Xingyu and Lai, Shenqi and Jiang, Wei. Bag of Tricks and a Strong Baseline for Deep Person Re-Identification. . [2] Wang, G. and Yuan, Y. and Chen, X. and Li, J. and Zhou, X. Learning Discriminative Features with Multiple Granularities for Person Re-Identification. . [3] Ye, Mang and Shen, Jianbing and Lin, Gaojie and Xiang, Tao and Shao, Ling and Hoi, Steven C. H.Deep Learning for Person Re-identification: A Survey and Outlook. . [4] Y. Sun, C. Cheng, Y. Zhang, C. Zhang, L. Zheng, Z. Wang, Y. Wei. Circle Loss: A Unified Perspective of Pair Similarity Optimization. .",
            "url": "https://l1aoxingyu.github.io/blogpages/reid/fastreid/2020/05/29/fastreid.html",
            "relUrl": "/reid/fastreid/2020/05/29/fastreid.html",
            "date": " • May 29, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Self-Supervised Learning 入门介绍",
            "content": "引子 . 最近 self-supervised learning 变得非常火，首先是 kaiming 的 MoCo 引发一波热议，然后最近 Yann 在 AAAI 上讲 self-supervised learning 是未来。 所以觉得有必要了解一下 SSL，也看了一些 paper 和 blog，最后决定写这篇文章作为一个总结。 . . 什么是 Self-Supervised Learning . 首先介绍一下到底什么是 SSL，我们知道一般机器学习分为监督学习，非监督学习和强化学习。 而 self-supervised learning 是无监督学习里面的一种，主要是希望能够学习到一种通用的特征表达用于下游任务。 其主要的方式就是通过自己监督自己，比如把一段话里面的几个单词去掉，用他的上下文去预测缺失的单词，或者将图片的一些部分去掉，依赖其周围的信息去预测缺失的 patch。 . 根据我看的文章，现在 self-supervised learning 主要分为两大类：1. Generative Methods；2. Contrastive Methods。 下面我们分别简要介绍一下这这两种方法。 . Generative Methods . 首先我们介绍一下 generative methods。 这类方法主要关注 pixel space 的重建误差，大多以 pixel label 的 loss 为主。 主要是以 AutoEncoder 为代表，以及后面的变形，比如 VAE 等等。 对编码器的基本要求就是尽可能保留原始数据的重要信息，所以如果能通过 decoder 解码回原始图片，则说明 latent code 重建的足够好了。 . . 这种直接在 pixel level 上计算 loss 是一种很直观的做法，除了这种直接的做法外，还有生成对抗网络的方法，通过判别网络来算 loss。 . 对于 generative methods，有一些问题，比如： . 基于 pixel 进行重建计算开销非常大； | 要求模型逐像素重建过于苛刻，而用 GAN 的方式构建一个判别器又会让任务复杂和难以优化。 | 从这个 blog 中我看到一个很好的例子来形容这种 generative methods。 对于一张人民币，我们能够很轻易地分辨其真假，说明我们对其已经提取了一个很好的特征表达，这个特征表达足够去刻画人民币的信息， 但是如果你要我画一张一模一样的人民币的图片，我肯定没法画出来。 通过这个例子可以明显看出，要提取一个好的特征表达的充分条件是能够重建，但是并不是必要条件，所以有了下面这一类方法。 . . Contrasive self-supervised learning . 除了上面这类方法外，还有一类方法是基于 contrastive 的方法。 这类方法并不要求模型能够重建原始输入，而是希望模型能够在特征空间上对不同的输入进行分辨，就像上面美元的例子。 . 这类方法有如下的特点：1. 在 feature space 上构建距离度量；2. 通过特征不变性，可以得到多种预测结果；3. 使用 Siamese Network；4. 不需要 pixel-level 重建。 正因为这类方法不用在 pixel-level 上进行重建，所以优化变得更加容易。当然这类方法也不是没有缺点，因为数据中并没有标签，所以主要的问题就是怎么取构造正样本和负样本。 . 目前基于 contrastive 的方法已经取得了很好的紧张，在分类任上已经接近监督学习的效果，同时在一些检测、分割的下游任务上甚至超越了监督学习作为 pre-train的方法。 . 下面是这两类方法的总结图片。 . . 为什么需要 self-supervised learning . 上面我们讲了什么是 self-supervised learning，那么为什么我们需要自监督学习呢，以及它能够给我们带来哪些帮助？ . 在目前深度学习发展的情况下，对于监督学习，我们希望使用更少的标注样本就能够训练一个泛化能力很好的模型，因为数据很容易获取，但是标注成本却是非常昂贵的。 而在强化学习中，需要大量的经验对 agent 进行训练，如果能搞减少 agent 的尝试次数，也能够加速训练。 除此之外，如果拿到一个好的特征表达，那么也有利于做下游任务的 finetune 和 multi-task 的训练。 . 最后我们总结一下监督学习和自监督学习的特点，其中 supervised learning 的特点如下： . 对于每一张图片，机器预测一个 category 或者是 bounding box | 训练数据都是人所标注的 | 每个样本只能提供非常少的信息(比如 1024 个 categories 只有 10 bits 的信息) | 于此对比的是，self-supervised learning 的特点如下： . 对于一张图片，机器可以预任何的部分 | 对于视频，可以预测未来的帧 | 每个样本可以提供很多的信息 | 所以通过自监督学习，我们可以做的事情可以远超过监督学习，也难怪 Yann 未来看好 self-supervised learning。 目前出现的性能很好的文章主要是基于 contrastive 的方法，所以下面我们介绍几篇基于 contrastive 方法的文章。 . Contrastive Predictive Coding . 第一篇文章是 Representation Learning with Contrastive Predictive Coding。 这篇文章主要是通过 contrastive 的方式在 speech, images, text 和 reinforcement learning 中都取得了很好的效果。 . 从前面我们知道，由一个原始的 input 去建模一个 high-level representation 是很难的，这也是自监督学习想做的事情。 其中常用的策略是: future，missing 和 contextual，即预测未来的信息，比如 video 中当前帧预测后面的帧；丢失的信息或者是上下文的信息，比如 NLP 里面的 word2vec 和 BERT。 . 对于一个目标 x 和他的上下文 c 来说，直接去建模输出 $p(x|c)$ 会损失很多信息，将 target x 和 context c 更合适的建模方式是最大化他们之间的 mutual information，即下面的公式 . I(x;c)=∑x,cp(x,c)log⁡p(x∣c)p(x)I(x; c)= sum_{x, c} p(x, c) log frac{p(x | c)}{p(x)}I(x;c)=x,c∑​p(x,c)logp(x)p(x∣c)​ . 优化了他们之间的互信息，即最大化 $ frac{p(x | c)}{p(x)}$，说明 $p(x|c)$ 要远大于 $p(x)$，即在给定 context c 的情况下， 要找到专属于 c 的那个 x，而不是随机采样的 x。 . 基于这个观察，论文对 density ratio 进行建模，这样可以保留他们之间的互信息 . fk(xt+k,ct)∝p(xt+k∣ct)p(xt+k)f_{k} left(x_{t+k}, c_{t} right) propto frac{p left(x_{t+k} | c_{t} right)}{p left(x_{t+k} right)}fk​(xt+k​,ct​)∝p(xt+k​)p(xt+k​∣ct​)​ . 对于这个 density ratio，可以构建左边的函数 f 去表示它，只要基于函数 f 构造下面的损失函数，优化这个损失函数就等价于优化这个 density ratio，下面论文会证明这一点。 . LN=−EX[log⁡fk(xt+k,ct)∑xj∈Xfk(xj,ct)] mathcal{L}_{ mathrm{N}}=- underset{X}{ mathbb{E}} left[ log frac{f_{k} left(x_{t+k}, c_{t} right)}{ sum_{x_{j} in X} f_{k} left(x_{j}, c_{t} right)} right]LN​=−XE​[log∑xj​∈X​fk​(xj​,ct​)fk​(xt+k​,ct​)​] . 而这个损失函数，其实就是一个类似交叉熵的函数，分子是正样本的概率，分母是正负样本的概率求和。 . 下面我们证明如果能够最优化这个损失函数，则等价于优化了 density ratio，也就优化了互信息。 . 首先将这个 loss 函数变成概率的形式，最大化这个正样本的概率分布，然后通过 bayesian 公式进行推导，其中 X 是负样本，和 $x_i$ 以及 c 都无关。 . p(xi∣X,ct)=p(X∣xi,ct)p(xi∣ct)∑j=1Np(X∣xj,ct)p(xj∣ct)=p(xi∣ct)∏l≠ip(xl)∑j=1Np(xj∣ct)∏l≠jp(xl)=p(xi∣ct)p(xi)∑j=1Np(xj∣ct)p(xj) begin{aligned} p left(x_i | X, c_{t} right) &amp;= frac{p(X | x_i, c_t) p(x_i | c_t)}{ sum_{j=1}^N p(X | x_j, c_t) p(x_j | c_t)} . &amp;= frac{p left(x_{i} | c_{t} right) prod_{l neq i} p left(x_{l} right)}{ sum_{j=1}^{N} p left(x_{j} | c_{t} right) prod_{l neq j} p left(x_{l} right)} &amp;= frac{ frac{p left(x_{i} | c_{t} right)}{p left(x_{i} right)}}{ sum_{j=1}^{N} frac{p left(x_{j} | c_{t} right)}{p left(x_{j} right)}} end{aligned}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;p(xi​∣X,ct​)​=∑j=1N​p(X∣xj​,ct​)p(xj​∣ct​)p(X∣xi​,ct​)p(xi​∣ct​)​=∑j=1N​p(xj​∣ct​)∏l​=j​p(xl​)p(xi​∣ct​)∏l​=i​p(xl​)​=∑j=1N​p(xj​)p(xj​∣ct​)​p(xi​)p(xi​∣ct​)​​​&lt;/span&gt;&lt;/span&gt; . 通过上面的推导，可以看出优化这个损失函数其实就是在优化 density ratio。论文中把 f 定义成一个 log 双线性函数，后面的论文更加简单，直接定义为了 cosine similarity。 . fk(xt+k,ct)=exp⁡(zt+kTWkct)f_{k} left(x_{t+k}, c_{t} right)= exp left(z_{t+k}^{T} W_{k} c_{t} right)fk​(xt+k​,ct​)=exp(zt+kT​Wk​ct​) . 有了这个 loss，我们只需要采集正负样本就可以了。 对于语音和文本，可以充分利用了不同的 k 时间步长，来采集正样本，而负样本可以从序列随机取样来得到。 对于图像任务，可以使用 pixelCNN 的方式将其转化成一个序列类型，用前几个 patch 作为输入，预测下一个 patch。 . . . Deep InfoMax . 通过上面的分析和推导，我们有了这样一个通用的框架，那么 deep infomax 这篇文章就非常好理解了，其中正样本就是第 i 张图片的 global feature 和中间 feature map 上个的 local feature，而负样本就是另外一张图片作为输入，非常好理解。 . . Contrastive MultiView Coding . 除了像上面这样去构建正负样本，还可以通过多模态的信息去构造，比如同一张图片的 RGB图 和 深度图。 CMC 这篇 paper 就是从这一点出发去选择正样本，而且通过这个方式，每个 anchor 不仅仅只有一个正样本，可以通过多模态得到多个正样本，如下图右边所示。 . . 现在我们能够拿到很多正样本，问题是怎么获得大量的负样本，对于 contrastive loss 而言，如何 sample 到很多负样本是关键，mini-batch 里面的负样本太少了，而每次对图片重新提取特征又非常的慢。虽然可以通过 memory bank 将负样本都存下来，但是效果并不好，所以如何节省内存和空间获得大量的负样本仍然没有很好地解决。 . MoCo . 有了上面这么多工作的铺垫，其实 contrastive SSL 的大框架已经形成了，MoCo 这篇文章也变得很好理解，可以把 target x 看成第 i 张图片的随机 crop，他的正样本通过一个 model ema 来得到，可以理解为过去 epochs 对这张图片的 smooth aggregation。 而负样本则从 memory bank 里面拿，同时 memory bank 的 feature 也是通过 model ema 得到，并且通过队列的形式丢掉老的 feature。 . . MoCo 通过工程的方式，和一些 trick，比如 model ema 和 shuffleBN 来解决之前没法很好 sample 负样本的问题。 . SimCLR . 最近，hinton 组也放了一篇做 ssl 的 paper，其实都是用的同一套框架，也没有太多的 novelty。 虽然摘要里面说可以抛弃 memory bank，不过细看论文，训练的 batchsize 需要到几千，要用32-128 cores 的 TPU，普通人根本用不起。 . 不过这篇文章系统地做了很多实验，比如探究了一下数据增强的影响，以及的 projection head 的影响等，不过也没有从理论上去解释这些问题，只是做了实验之后获得了一些结论。 . Results . . 最后展示了不同方法的结果，可以看到在性能其实已经逼近监督学习的效果，但是需要 train 4x 的时间，同时网络参数也比较大。 . 虽然性能没有超过监督学习，不过我认为这仍然给了我们很好的启发，比如训练一个通用的 encoder 来接下游任务，或者是在 cross domain 的时候只需要少量样本去 finetune，这都会给实际落地带来收益。 . Reference . contrastive self-supervised learning . deep infomax 和 深度学习中的互信息 .",
            "url": "https://l1aoxingyu.github.io/blogpages/summary/self-supervised%20learning/2020/02/20/ssl-survey.html",
            "relUrl": "/summary/self-supervised%20learning/2020/02/20/ssl-survey.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "A Simple Framework for Contrastive Learning of Visual Representations" 阅读笔记",
            "content": "介绍 . 这篇文章是 Hinton 团队出品的，主要做的是目前炙手可热的领域，self supervised learning， 提出了一个简单的框架来解决 visual representation 中的 contrastive learning。 其实前两个月 kaiming 团队也提出了一个叫 MoCo 的方法来解决这个问题，这篇文章总体思路和 MoCo 几乎一样，最大的 contribution 我认为是去探索了框架中的每个部分分别对最终结果的影响。 最后根据论文的发现，作者调出了目前最强的结果如下，点数非常高。 . . 主要贡献 . SimCLR 整体框架如下，和目前其他的方法是一致的 . . 主要由四个部分组成： . 随机数据增强 | 神经网络 encoder | project head $g( centerdot)$ 进行非线性映射和降维 | contrastive loss 函数 | li,j=−log⁡exp⁡(sim(zi,zj)/τ)∑k≠iexp⁡(sim(zi,zk)/τ)l_{i,j} = - log frac{ exp(sim(z_i, z_j)/ tau)}{ sum_{k neq i} exp(sim(z_i, z_k)/ tau)}li,j​=−log∑k​=i​exp(sim(zi​,zk​)/τ)exp(sim(zi​,zj​)/τ)​ . Memory bank . 这篇文章提出了可以去掉 memory bank 进行训练，实际上并不可行。 因为作者使用了 8192 的 batch size，这样每个 batch 可以产生 16382 个负样本。 当然当前 batch 提取的 feature 对比 memory bank 更好，但是这需要 128 cores 的 TPU 进行训练，对于财大气粗的 google 当然用得起，对于普通的研究人员来讲，还是老老实实用 memory bank 吧。 . Global BN . 使用 contrastive loss 进行训练的时候，正样本是一张相同的图片通过不同的数据增强方式得到的，这两张图片都在相同的 batch 中，这样非常因为 bn 统计量的问题出现信息泄露。 这篇文章使用了 global bn 的方式来就解决，即大 batch 下面，使用所有图片统计 bn 的均值和方差。 当然使用 MoCo 中的 suffle bn 也是可以的。 . 数据增强 . 本文系统的探索了数据增强对于表示学习的影响，其中 random cropping 和 random color distortion 是非常有用的。 random cropping 可以产生很多小 patch，但是这些小 patch 有着非常相似的颜色分布，所以可以用 color distortion 去弥补这个问题。 . Projection Head . 不同的 head 也有着不同的影响 . . 可以看出，直接使用 global average feature 效果是最差的，而一个 non-linear head 有着最好的效果。 . 其他的因素 . 除了上面这些因素之外，还用 contrastive loss 中的 temperatual factor $ tau$ 的影响，以及是否对 feature 做归一化。 当然这些在别的 paper 中都有了结论，这里就不再赘述。 . 另外还有 batch size 的影响，因为其没有用 memory bank，当然 batch size 越大，包含越多的负样本，效果越好。 . 总结 . 总体来说，这篇文章通过了很多实验来验证到底是哪些因素影响了 SSL 的效果。 很多结论也非常 solid，效果也非常好，可以指导很多调参的工作， 但是 novelty 上并没有给人太大的启发。 .",
            "url": "https://l1aoxingyu.github.io/blogpages/self-supervised%20learning/2020/02/15/simclr.html",
            "relUrl": "/self-supervised%20learning/2020/02/15/simclr.html",
            "date": " • Feb 15, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Currently, Xingyu is working as the Researcher Engineer in JD AI Lab. . Before that, Xingyu received his M.Sc.’s degree in USTC (University of Science and Technology of China). . Research Interests . Xingyu’s current research interests mainly include machine learning, computer vision, especially on deep learning, visual recognition and person re-identification. .",
          "url": "https://l1aoxingyu.github.io/blogpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://l1aoxingyu.github.io/blogpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}